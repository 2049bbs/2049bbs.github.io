---
aid: 6250
cid: 8
authorID: 3619
addTime: 2020-07-11T07:20:00.000Z
title: 【霏艺所思】霏藝眼裏的大數據
tags:
    - 所思
comments:
    -
        authorID: 3619
        addTime: 2020-07-11T08:20:00.000Z
        content: >-
            感覺大數據被雲計算衝擊的很厲害


            大數據的存儲，被雲存儲替代了


            大數據的計算，也有k8s和 虛擬化解決方案


            感覺，神經網絡，也可以用MPI去實現。


            就是感覺 ，現在 還説大數據，就不知道應用點在哪裏？


            * * *


            區塊鏈，感覺熱度下去了吧？


            一致性算法，感覺Raft ， Paxos更多些，真有人用Pow去做一致性麽？


            * * *


            VR好像熱度也下去了


            Google 好像不搞VR了？


            不知道現在的WebXR是什麽情況


            * * *


            我感覺，IT行業泡沫真大啊。。。


            也許是我不懂吧


            不是很喜歡現在，特別浮躁，動不動就一個概念


            沒有人踏踏實實做技術


            感覺年輕人都是兩個極端


            1.  注重論文，看了很多，寫了很多，就是不肯寫代碼【光說理論，紙上談兵的感覺】
                
            2. 
            不看論文，光是跟風。天天說“這個死了”，“那個主流”。代碼水平也許很好吧，也看了很多開源項目。但是技術沒有任何沉澱，也不是很懂算法。感覺就是跟風使用各種開源項目。
                

            * * *


            紙上得來終覺淺，絕知此事要躬行


            做學術，不能浮躁。先去想想，我要解決什麽問題。給自己立下一個課題。


            然後，開始學習相關的技術和論文。


            最後開始自己，找個解決辦法。用編程，用算法去實現。


            這個時候，就是踩坑了！就是踩坑的時候，我們才知道，我們需要做什麽細節。


            也就是這些細節，是最寶貴的經驗。因爲這些細節。我們的論文才有價值。


            比如Relu這個激活函數，就是在事件中發現的。


            當然，後來，我們都搞gelu了


            然後sgd也換成了adam


            但是，這些細節，都需要我們去實踐！


            不去實踐，你永遠發現不了自己該去幹什麽


            光寫論文是沒用的，還是需要去寫代碼，實現別人的論文


            或者實現自己的論文，發現一些不足，自己要去改進


            所以，這個才是做學術的態度
    -
        authorID: 3793
        addTime: 2020-07-11T08:20:00.000Z
        content: |-
            感谢分享。

            话说，我觉得“大数据”这个词多年来被媒体严重滥用了。
    -
        authorID: 3619
        addTime: 2020-07-12T15:20:00.000Z
        content: |-
            假設銀行記錄了每條客戶操作記錄為100字節

            每天100條

            那麽一年大概消耗4MB的硬盤

            假設，銀行用戶10億，每年可以產生4PB的用戶數據

            考慮到雙活，那麽預估，中國的銀行，每年硬盤數據增長就高達10PB

            * * *

            考慮嗶哩嗶哩

            每條用戶操作都記錄數據庫

            每條記錄100字節，每天100條，每個用戶一年可以產生4MB的數據

            假設用戶4億人，那麽1.6PB，考慮3副本備份，那麽就是5PB

            * * *

            所以，“金融，通信，交通，互聯網”行業在數據存儲問題上，一定會遇到大數據的問題。

            通過以前 SAN ，陣列等存儲方式，必然有很高的成本問題，通過分佈式文件系統可以緩解

            但是現在出現了更加便宜的雲存儲方案
    -
        authorID: 4953
        addTime: 2020-07-12T15:40:00.000Z
        content: >-
            [](#spark-vs-mapreduce)spark vs mapreduce

            -----------------------------------------


            Spark facilitates the implementation of both iterative algorithms,
            which visit their data set multiple times in a loop, and
            interactive/exploratory data analysis, i.e., the repeated
            database-style querying of data.


            Spark相较于mapreduce的优势在于：一、迭代计算更快。就是多步骤的，多步的map、reduce、map、reduce……,
            可以在内存中完成，不用每次都存盘/读盘。二、支持交互式查询。
    -
        authorID: 3619
        addTime: 2020-07-11T16:00:00.000Z
        content: |-
            考慮嗶哩嗶哩的視頻，平均200MB，平均每天上傳4萬個，

            那麽每年存視頻，需要消耗3PB，考慮到3副本備份，就是9PB

            算是用戶數據活動，就是14PB

            感覺現在開個互聯網公司，對硬盤的消耗真是巨大啊

            * * *

            假設每個http請求，消耗4KB， 如果服務器的上行帶寬100Mbps，那麽大概可以承受3000個請求的并發

            如果是看視頻，那麽以720p分辨率來計算，理論可以支持50路視頻的并發

            假設，我自己開個嗶哩嗶哩這樣的網站

            有10億用戶，那麽http的并發按3%計算，需要1萬臺服務器去抗http請求

            假設，需要額外1萬臺服務器用來做視頻服務器

            那麽額外的需要5000台服務器，作爲數據庫服務器

            那麽服務器需要2.5萬台服務器起碼吧？

            每臺服務器按1萬計算，就是2.5億，還有這些服務器的電費，寬帶費

            人力成本，各種稅收。。。

            開個公司不容易啊。。。都是錢啊

            * * *

            開個小公司好了

            不保存用戶的操作記錄【省了好多硬盤錢】

            假設用戶數量是10萬級別【預估數據庫的大小是1TB】

            數據量比較小，估計不用上分佈式數據庫了【上一套Oracle就可以了，做雙活】

            并發按3%計算，也就是3000，那麽一臺服務器就可以抗住并發了【應用服務器主備，所以配置兩臺】

            應用服務器，打算用OpenResty做API【性能好，可以高并發】

            後端用FastAPI寫服務，再在騰訊云上買個GPU云用來訓練

            感覺基本就可以抗下IT的需求了吧？

            1.  不用Java，太吃内存了，使用OpenResty可以抗住相同并發的情況下，更加省内存
                
            2.  不用微服務，一個服務就應該把業務都完成，每個服務一個進程太吃内存，所有服務都寫到一個進程足夠了
                
            3.  nginx前置負載均衡就可以了，後面數據庫雙活。就可以不用部署分佈式了
                

            還是小公司運營簡單。。。

            公司大了以后，運維完全就不會了。。。

            大公司，服務器動不動就是幾千臺，動不動就是一個集群，好幾個機房

            沒那個本事管理這麽多電腦~

            * * *

            什麽時候能上IPv6啊！！！

            天天内網穿透，很討厭！！

            美國IPv6都普及4成了，中國才0.24%，氣死我了！！！
    -
        authorID: 3619
        addTime: 2020-07-11T16:00:00.000Z
        content: |-
            @[spark](/member/spark) #4 你説的這兩點，我前面已經説了

            不過，Spark和Hadoop，我都沒有用過。。。

            我也不是做大數據的

            我是外行，你不用理會我胡言亂語的
    -
        authorID: 4953
        addTime: 2020-07-14T05:20:00.000Z
        content: |-
            你这里说的是指像亚马逊的Aurora数据库吗？

            > 大數據的存儲，被雲存儲替代了

            k8s与spark是什么关系？

            > 大數據的計算，也有k8s和 虛擬化解決方案
    -
        authorID: 3619
        addTime: 2020-07-15T14:20:00.000Z
        content: |-
            @[spark](/member/spark) #7

            指的是亞馬遜的S3這些雲存儲

            我説的是大數據的計算，指的是應用方向。不是指計算引擎。

            spark可以跑在yarn和k8s這些資源調度系統下。我不是說這個。

            阿里雲，Azure，AWS提供了大量的API來實現統計分析之類的功能，企業自己搭建Spark這些集群的動力不大了

            我指的是，大數據的計算方向，更多人選擇了雲計算提供的API，而不是自己搭建Spark這些集群
    -
        authorID: 4953
        addTime: 2020-07-15T14:20:00.000Z
        content: |-
            云计算API是什么？怎么用？我在网上搜了一下，这个算不算？

            https://cn.aliyun.com/product/man
    -
        authorID: 3619
        addTime: 2020-07-15T14:20:00.000Z
        content: >-
            @[spark](/member/spark) #9
            https://docs.aws.amazon.com/kinesis/index.html


            我指的是這類東西


            * * *


            大數據的東西我不懂，我都是用Matlab，下面的人用的是TensorFlow【單機，不是集群】


            我是從來沒用過Spark【Hadoop生態系統，我都沒有用過】


            大數據，雲計算，我都不懂~


            我只是隨便看了看AWS的產品


            看到它推出了S3，用來提供大數據的存儲業務


            推出了一堆API，用來提供大數據的計算業務


            大數據的批處理，我覺得Spark應該比較主流


            流計算，貌似更多人選擇了Flink，或者Storm，看需求吧


            我是不信有多少公司會花錢買一堆機房，部署分佈式Spark集群，還養一群運維


            自己搭建Spark集群的代價太大了，不是集群，就沒有必要部署Spark了吧？


            單機Spark的意義在哪裏？
date: 2020-07-15T14:20:00.000Z
category: 博客
---

**我不是做大數據的，所以都是外行下琢磨而已**

### [](#%E5%A4%9A%E5%A4%A7%E7%9A%84%E6%95%B8%E6%93%9A%E7%AE%97%E5%A4%A7%E6%95%B8%E6%93%9A)多大的數據算大數據？

三個情況：

1.  單機存不下的**單個大文件**【比如10TB的超級大文件】
    
2.  單機存不下的**超多數量文件**【比如几千億張圖片】
    
3.  單機處理不了的數據量
    

一般把單機解決不了的問題，定義為大數據。

所以大數據可以分爲兩個問題：“數據怎麽存”和“數據怎麽用”

### [](#%E4%BB%80%E9%BA%BD%E6%98%AFmapreduce)什麽是mapreduce？

我們從數據怎麽用開始講起吧~

比如，我現在有一組數據，我想找到這個數據裏的最小值

我們把前一個數據的結果和後面這個數據比較，這個過程就是reduce了

    比如 sum = 0， sum = sum + element[i]
    

這個就是最基本的reduce

再比如，我有一個城市所有人的數據，

我知道他們的出生年月，現在要計算他們的年紀 = 2020 - 他們的出生年

這個過程就是map了

    birthyear_list = 保存了所有人的出生年份，list結構
    age_map(list) =  2020 - list 計算list的年紀，遍歷list每個元素，執行這個map函數
    

現在連起來思考，我得到了整個城市所有人的出生年份

現在計算誰的年紀最大。

map函數計算大家的年份，reduce函數計算誰的年紀最大

    所有人的出生年份.mapper(2020-birth).reduce(a>b?a:b)
    

mapreduce，講解完畢~

### [](#%E7%88%B2%E4%BB%80%E9%BA%BD%E5%88%97%E5%BC%8F%E5%AD%98%E5%84%B2)爲什麽列式存儲？

大家都看到了，map和reduce的入參，是一個**數據類型相同**的list！

如果是傳統的行式存儲，我需要這麽寫代碼

    // 查找整個城市的所有人裏年紀最大的人的歲數
    // table 表示 一個表 存了所有人的個人信息，出生年份記錄在第七列
    list = []
    遍歷 table :
           讀取一行數據 放到 row
           讀取row的第7列 ，放到year
          list.append(year)
    
    list.map(2020-year).reduce(a>b?a:b)
    
    

再來看看列式存儲

    // 查找整個城市的所有人裏年紀最大的人的歲數
    // table 表示 一個表 存了所有人的個人信息，出生年份記錄在第七列
    table[7].map(2020-year).reduce(a>b?a:b)
    

因爲列式儲存，所以可以直接拿出一列的數據【就像行式存儲，每次拿到一行數據】 所以，列式存儲，非常適合map reduce操作！！！【省時間，省空間，速度非常快】

### [](#%E5%A4%A7%E6%95%B8%E6%93%9A%E6%80%8E%E9%BA%BD%E5%AD%98)大數據怎麽存？

Google爲了解決數據的存儲問題，首先就構建了一個分佈式存儲文件系統GFS

這樣就可以存很大很大的文件了【數據庫文件】

光是裸數據，不方便使用啊。所以要用數據庫來管理。

然後爲了後續使用方便，所以在分佈式文件系統GFS上，開發了列式存儲的數據庫BigTable

開源項目Hadoop，分別實現了GFS和BigTable【取名字是HDFS和HBase】

### [](#%E5%A4%A7%E6%95%B8%E6%93%9A%E6%80%8E%E9%BA%BD%E7%94%A8)大數據怎麽用？

關於數據怎麽用，就是我説的mapreduce了，Hadoop也實現了Mapreduce

不過，現在已經被Spark替代了

對數據map以後，分給n多個小電腦，分別處理，在統一回收，得到新的list

把list再給reduce，整個過程都是分佈式的

spark是一種特殊的存在，主要優勢就是内存計算【可以交互】

mapreduce看上去很簡單，實際也很簡單，用map reduce寫代碼，就像匯編寫程序，你説能不能幹活，肯定可以！但是效率太慢了，寫起來囉嗦！還容易寫錯！

所以就想，能不能搞點高級語言？

然後封裝了Pig和Hive【Hive可以實現類似SQL的方式操作分佈式存儲系統】

爲什麽會這樣呢？

數據庫可以大致分爲 OLTP和 OLAP

OLTP就是，我們常説的CRUD，説到CRUD自然想到 SQL，所以我們覺得可以用SQL來寫分佈式計算，滿足一定的需求【Spark SQL 應運而生】

OLAP就是，我們常説的統計，分析，聚類。。。然後説到統計，我們就想到了R語言。然後SparkR就出現 了~

分佈式除了儅數據庫，還可以用來做很多事情

比如神經網絡，訓練需要很多計算資源，用Spark可以實現分佈式計算，MLlib

再比如圖數據庫，GraphX

計算24小時的熱詞，搜索等等 Spark Streaming

spark生態系統就這麽一堆東西出來了~

Spark可以跑在集群上，比如yarn ，k8s

數據源可以是HBase，Hive，Cassandra等等。。。

### [](#%E6%A0%B9%E6%93%9A%E6%95%B8%E6%93%9A%E7%B5%90%E6%A7%8B%E5%88%86%E9%A1%9E%E6%95%B8%E6%93%9A%E5%BA%AB)根據數據結構分類數據庫

如果說程序 就是 數據結構 + 算法

那麽數據庫 就是 存儲結構 + 計算引擎

計算引擎 現在基本就是 Spark了

那麽存儲結構有哪些呢？

1.  Vector結構 ： 時序數據庫 influxdb
    
2.  List 結構 ： 區塊鏈
    
3.  Map結構 ： Redis
    
4.  Tree結構： MongoDB
    
5.  Table結構 ： MySQL
    
6.  Graph結構： Neo4J
