---
aid: 1845
cid: 5
authorID: 2280
addTime: 2019-11-17T16:30:00.000Z
title: Google使用算法技术以外的手段人工干预排序。
tags:
    - google
    - 算法
    - 技术
    - 手段
comments:
    -
        authorID: 1
        addTime: 2019-11-17T16:30:00.000Z
        content: >-
            **auto-complete feature**
            是真的必须人工介入，我对人工介入没什么不满，关键是希望这里面有明确的规范，而不是黑箱。


            我比较赞成拆分 Google，搜索就和印钞一样，想要不作恶太难了。


            另外就是 Google 作为铁杆民主党，不知道这个报道会不会被用来证明干预大选。
    -
        authorID: 2243
        addTime: 2019-11-17T16:30:00.000Z
        content: >-
            我朋友他们公司（媒体）用的google 企业云，有专门的search engine optimization 部门，与google
            商量如何更好的提交site map~~


            另 Facebook 前几天好像因为用户数据问题（Cambridge Analytica scandal）去了国会听证会：


            "Advertisers tell us who they want to reach and we do the
            placement," Zuckerberg said. "We do not sell data to advertisers."


            [https://www.cnet.com/news/congress-to-grill-facebook-zuckerberg-over-data-mining-election-meddling-cambridge-analytica/](https://www.cnet.com/news/congress-to-grill-facebook-zuckerberg-over-data-mining-election-meddling-cambridge-analytica/)
    -
        authorID: 2523
        addTime: 2019-11-17T16:30:00.000Z
        content: <strike>用户已注销，隐藏回帖</strike>
    -
        authorID: 2280
        addTime: 2019-11-17T16:30:00.000Z
        content: >-
            @[小二](/member/%E5%B0%8F%E4%BA%8C) #1


            为什么必须需要人工干预呢？人的目的和想法太多了，人工干预就是一个zero-sum，希望出现的那个词赢了，被人工干预消失的那个词输了...
            用算法比较直接和透明吧...


            我其实同意Yahoo/DuckDuckGo的方法，要不不显示auto-complete（如果联想的词太offensive），如果显示auto-complete就不要任何人工干预。


            > Gabriel Weinberg, DuckDuckGo’s chief executive, said that for
            certain words or phrases entered into the search box, such as ones
            that might be offensive, DuckDuckGo has decided to block all of its
            auto-complete suggestions, which it licenses from Yahoo.


            我个人是讨厌任何人工干预，提倡一切交由算法的（这也是2006年之前的google的核心原则）...


            * * *


            看看WSJ这篇文章的影响吧，我是从这篇文章中读出了不单影响搜索引擎的竞争，而且通过支持大公司打压小公司从而影响了其他行业的竞争的这种结论。如果是这样，那么拆分就是自然而然的结论了。


            * * *


            政治的方面我不懂... 但是文章的确隐含了google打压conservative偏好liberal的意思...
    -
        authorID: 2280
        addTime: 2019-11-17T16:30:00.000Z
        content: >-
            @[Merlin](/member/Merlin) #2


            这个行为，我看来是影响了公司之间的competition了，特别是出钱越多的公司（一般是大公司）更能得到越多的信息，小公司没钱得到的exposure就小；长久以后，市场准入的门槛就越来越高；市场最后就变成了monopoly
            或者 oligopoly... 苦了消费者...


            * * *


            facebook的数据管理臭名昭著... 话说我之前还有一些他们的用户数据做social network mapping...


            不知道包不包括2049上各位的数据....：）
    -
        authorID: 2523
        addTime: 2019-11-17T16:30:00.000Z
        content: <strike>用户已注销，隐藏回帖</strike>
    -
        authorID: 1
        addTime: 2019-11-17T16:30:00.000Z
        content: >-
            @[xyz](/member/xyz) #4 联想词很容易出现你所说的 offensive case
            的问题，这个问题的本质就是，机器学习是从人产生的数据中学习，人是怎样，机器就学成那个样子。但是，我们都知道有些东西符合人性，比如色情，歧视，脏话等，但是不能出现在正式场合，这种情形就需要人工介入，去定义这些
            special case。
    -
        authorID: 2280
        addTime: 2019-11-17T17:15:00.000Z
        content: >-
            @[勃列日涅夫](/member/%E5%8B%83%E5%88%97%E6%97%A5%E6%B6%85%E5%A4%AB) #3


            这个我认为还是公说公有理，Google提供了算法，其他人explore算法，我认为是合理的；如果Google觉得不公平，那它可以改变更新算法。另外Ebay的说法是：这不是一个单一的事件，是长期的持续的打击（“We’ve
            experienced significant and consistent drops in Google SEO for many
            years”）


            具体的WSJ关于EBay的讨论如下。


            > Online marketplace eBay had long relied on Google for as much as a
            third of its internet traffic. In 2014, traffic suddenly
            plummeted—contributing to a $200 million hit in its revenue guidance
            for that year.

            > 

            > Google told the company it had made a decision to lower the
            ranking of a large number of eBay pages that were a big source of
            traffic.

            > 

            > EBay executives debated pulling their quarterly advertising
            spending of around $30 million from Google to protest, but
            ultimately decided to step up lobbying pressure on Google, with
            employees and executives calling and meeting with search engineers,
            according to people familiar with the matter. A similar episode had
            hit traffic several years earlier, and eBay had marshaled its
            lobbying might to persuade Google to give it advice about how to fix
            the problem, even relying on a former Google staffer who was then
            employed at eBay to work his contacts, according to one of those
            people.

            > 

            > This time, Google ultimately agreed to improve the ranking of a
            number of pages it had demoted while eBay completed a broader
            revision of its website to make the pages more “useful and
            relevant,” the people said. The revision was arduous and costly to
            complete, one of the people said, adding that eBay was later hit by
            other downrankings that Google didn’t help with.

            > 

            > “We’ve experienced significant and consistent drops in Google SEO
            for many years, which has been disproportionally detrimental to
            those small businesses that we support,” an eBay spokesman said.
            SEO, or search-engine optimization, is the practice of trying to
            generate more search-engine traffic for a website.
    -
        authorID: 2280
        addTime: 2019-11-17T17:15:00.000Z
        content: >-
            @[勃列日涅夫](/member/%E5%8B%83%E5%88%97%E6%97%A5%E6%B6%85%E5%A4%AB) #6


            > 算法并不见得比人公正。人是有偏见的，算法同样有偏见。auto-complete联想出来的一系列偏见的结果。


            嗯嗯，我同意。我的想法是与其用google工程师的偏见去纠正用户的偏见，还不如在出现有争议的内容时取消这些auto-complete，就像yahoo一样。如果有google工程师的介入，定义什么是“合适的可以出现的”auto-complete，那么只是在用google工程师的偏见去覆盖用户的偏见，都不可取...


            > 搜索引擎是在跟人斗，不是在跟机器斗。网站为了排名高，会不断发明出各种新的作弊手段。算法跟不上，算法判断不出来，就需要人工干预。


            这个我认为这就是猫捉老鼠啦，出现作弊手段，google就可以去补漏改进算法。如果说算法判断不出来，需要人工干预，我觉得是google的工程师不够努力...
            呃，我好像过于资本主义的嘴脸了...


            @[小二](/member/%E5%B0%8F%E4%BA%8C) #7


            > 联想词很容易出现你所说的 offensive case
            的问题，这个问题的本质就是，机器学习是从人产生的数据中学习，人是怎样，机器就学成那个样子。但是，我们都知道有些东西符合人性，比如色情，歧视，脏话等，但是不能出现在正式场合，这种情形就需要人工介入，去定义这些
            special case。


            和回复 @[勃列日涅夫](/member/%E5%8B%83%E5%88%97%E6%97%A5%E6%B6%85%E5%A4%AB)
            ，差不多，我觉得只要是人都有偏见；不存在一个偏见好于另一个偏见；我们需要的是如何定义我们认为好，它的标准是什么，如何识别，把这些规则给算法，让算法去判断。


            我个人倾向于：人是制定规则，机器是执行规则的；当机器执行的规则导致的结果是人不想要的，那么人应该改进规则，而不是帮机器去执行规则。
    -
        authorID: 2523
        addTime: 2019-11-17T18:00:00.000Z
        content: <strike>用户已注销，隐藏回帖</strike>
    -
        authorID: 2523
        addTime: 2019-11-17T18:30:00.000Z
        content: <strike>用户已注销，隐藏回帖</strike>
    -
        authorID: 2534
        addTime: 2019-11-17T20:30:00.000Z
        content: >-
            @[xyz](/member/xyz) #9
            @[勃列日涅夫](/member/%E5%8B%83%E5%88%97%E6%97%A5%E6%B6%85%E5%A4%AB) #10
            @[小二](/member/%E5%B0%8F%E4%BA%8C) #7 这个话题让我想起一个哲学问题：


            [](#%E4%BA%BA%E5%88%B0%E5%BA%95%E8%83%BD%E5%A4%9F%E5%92%8C%E5%BA%94%E8%AF%A5%E6%89%BF%E5%8F%97%E5%A4%9A%E5%B0%91%E7%9C%9F%E7%9B%B8)人到底能够和应该承受多少真相？

            --------------------------------------------------------------------------------------------------------------------------------------------------


            世界上有很多丑陋邪恶，如果把他们全部一五一十的呈现给每个人，会有什么后果？比方说血腥、尸体的照片、强奸杀人现场视频，以及各种阴谋诡计、背后运作，也包括每个人内心的偏见、歧视、仇恨、矛盾等等。


            美国的媒体行业，编辑作为看门人，有审查不适合的内容和危害公共安全的机密的职责。如果说AI+大数据能在相当程度上了解世界的真相，那么在向公众呈现AI的输出结果时，也会面临跟传统媒体同样的道德责任。


            现在AI研究行业已经发起了关于机器道德的研究，就是为了处理这类问题。比方说自动驾驶汽车的AI在车祸不可避免时是该选择杀死自己的主人还是5个无辜路人？而搜索引擎的问题似乎应该从传统媒体内容审查的道德辩论去寻找答案。
    -
        authorID: 2280
        addTime: 2019-11-18T03:45:00.000Z
        content: >-
            @[勃列日涅夫](/member/%E5%8B%83%E5%88%97%E6%97%A5%E6%B6%85%E5%A4%AB) #10
            #11


            > Google似乎也像政府一样，要增加透明度、可问责。这点绝对没错。


            我其实很矛盾。一方面google的影响实在太大，它提供的服务都不像一个可选择的私人商品，都像一个utility了，对这种utility（类似于水，电），增加透明和问责我的确支持。另一方面，又有点担心扩大政府的影响和权力（想象一下由政府来监督什么样的信息才能出现在搜索结果中这种恐怖情况），私人企业和公民的权力越来越不能制约政府权力了。矛盾啊...


            >
            比如为什么要靠人工标注（contractors）选择他们喜好的排序。其实人工智能算法很大的一类是“有监督的学习”，就是从人工标注的数据中学习，没有人工标注就没有人工智能了，这是免不了的。


            是啊，contractors应该就是用来帮semi-supervised learning或者supervised
            learning标注的吧... 其实我很好奇，为什么不能用unsupervised
            learning呢？Google不担心因为这些contractors的偏见导致标注出现偏差，从而人工智能学习的结果也会展示这种偏见吗？


            最近在学习machine learning的知识，但是主要集中在大数据和数据降维的理论这一块，还没有碰过supervised
            learning这一块... 能否解释一下为啥google选择supervised learning这种吗？


            >
            从它的叙述没有看出Google是为了敲诈ebay的广告费才降低它的排名。甚至能看出排名与是不是大金主无关，因为ebay就是在Google投放了大量广告。


            嗯嗯嗯，我主要的担心是连Ebay这种大公司都有可能被google所威胁和影响，不用说其他小公司了...
            从这点上看，我支持拆了google...


            > 没有投广告就不给协助了,这条确实问题比较大。


            嗯嗯嗯，同意，影响了其他行业的公平竞争原则...
    -
        authorID: 2280
        addTime: 2019-11-18T03:45:00.000Z
        content: |-
            @[alexanderya](/member/alexanderya) #12

            先把Asimov's Laws搞起来...
    -
        authorID: 2523
        addTime: 2019-11-18T21:00:00.000Z
        content: <strike>用户已注销，隐藏回帖</strike>
    -
        authorID: 2280
        addTime: 2019-11-19T01:00:00.000Z
        content: >-
            @[勃列日涅夫](/member/%E5%8B%83%E5%88%97%E6%97%A5%E6%B6%85%E5%A4%AB) #15


            嗯嗯，这些contractors应该是给algorithm提供training的，并不是直接影响排名，只能通过training来影响...


            应该是这样理解吧...
    -
        authorID: 2523
        addTime: 2019-11-19T10:45:00.000Z
        content: <strike>用户已注销，隐藏回帖</strike>
    -
        authorID: 2280
        addTime: 2019-11-19T23:00:00.000Z
        content: |-
            @[勃列日涅夫](/member/%E5%8B%83%E5%88%97%E6%97%A5%E6%B6%85%E5%A4%AB) #17

            嗯嗯，多谢解释，我完全同意：）
    -
        authorID: 2523
        addTime: 2019-11-20T01:45:00.000Z
        content: <strike>用户已注销，隐藏回帖</strike>
    -
        authorID: 2280
        addTime: 2019-11-20T16:45:00.000Z
        content: >-
            @[勃列日涅夫](/member/%E5%8B%83%E5%88%97%E6%97%A5%E6%B6%85%E5%A4%AB) #19


            呃，读了一下，这些审核员也很辛苦啊... 熬大夜，而且没有技术含量，学不到东西。


            让我想起了以前看过的一个关于youtube外包censorship 的report，现在找不到了，也是这种labor
            intensive的工作...
            但是这种工作是那些审核员所能找到的最好的工作了，当youtube慢慢转向AI以后这些工作慢慢地也会消失...
            听上去很悲伤很无赖的感觉...


            唉，好像只要是有supervised
            的learning，好像supervisor的偏见都是不可避免的。希望以后多搞点unsupervised learning吧...
            或者supervisor只判断事实（比如这张图片是否露点），而不判断价值（这张图片是否是色情）也可以...
    -
        authorID: 2157
        addTime: 2019-11-21T05:45:00.000Z
        content: >-
            @[xyz](/member/xyz) #20 我似乎也看过类似的文章，审核员的心理健康问题，今年年初有过一阵热度。


            [https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona](https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona)


            [https://www.npr.org/2019/07/01/737498507/for-facebook-content-moderators-traumatizing-material-is-a-job-hazard](https://www.npr.org/2019/07/01/737498507/for-facebook-content-moderators-traumatizing-material-is-a-job-hazard)
    -
        authorID: 2280
        addTime: 2019-11-21T16:30:00.000Z
        content: >-
            @[懦夫斯基](/member/%E6%87%A6%E5%A4%AB%E6%96%AF%E5%9F%BA) #21


            的确很像...
            这种生理和心理的摧残的确很让人痛苦，还是希望早点实现完全用AI来filter暴力和血腥的内容，人看久了真的会出问题的...
date: 2019-11-21T16:30:00.000Z
category: 分享发现
---

昨天WSJ的头条大字报，占了周六Exchange栏目的三页纸，好不容易读完了，分享一下我自己的摘要：

网络版本： [https://www.wsj.com/articles/how-google-interferes-with-its-search-algorithms-and-changes-your-results-11573823753](https://www.wsj.com/articles/how-google-interferes-with-its-search-algorithms-and-changes-your-results-11573823753)

* * *

**Google用了编辑的方法改变用户的搜索排序**

*   靠“人工”智能（真正的私人contractors）选择他们喜好的排序，以此为标准更新搜索（Zack Langley of Lionbridge Technologies Inc.的表述；“Mr. Langley was given hundreds of real search results and told to use his judgment to rate them according to quality, reputation and usefulness, among other factors.”； “Mr. Langley said it seemed like Google wanted him to change content on search so Google would have what he called plausible deniability about making those decisions. He said contractors would get notes from Lionbridge that he believed came from Google telling them the “correct” results on other searches.”）
*   靠内部的“go/bad reporting system”人工干预算法排序（“how do vaccines cause autism”的例子）
*   有一些网站在blacklists中 ("The Gateway Pundit" & "The United West")；有一些网站被人工提高或减低排序(abortion的例子；conservative的网站和blog) ("Google’s shifting policies on interference—and its lack of transparency about them—inevitably force employees to become arbiters of what is acceptable, a dilemma that opens the door to charges of bias or favoritism.")
*   政府 2016年以后要求了大量的人工干预移除一些搜索结果 （“Nearly 78% of those removal requests have been since the beginning of 2016”）
*   Google不再强调free expression （“Google’s culture of publicly resisting demands to change results has diminished, current and former employees said.”）

**编辑的重灾区是“auto-complete feature”**

*   因该是人工删除了一些联想词 （"less inflammatory than those of the other engines"）
*   有人工制定的blacklists

**Google的人工编辑更偏好大公司**

*   这个其实有非常严重的anti-competitive的问题，以此为理由其实可以要求对google进行oversight或者拆分...（“engineers opted to tilt results to favor prominent businesses over smaller ones, based on the argument that customers were more likely to get what they wanted at larger outlets. ”）
*   大客户会收到更多的信息帮助他们提高搜索排序 （“Some very big advertisers received direct advice on how to improve their organic search results, a perk not available to businesses with no contacts at Google”）
*   对大公司的更新更快 （“Google updates its index of some sites such as Facebook and Amazon more frequently, a move that helps them appear more often in search results”）
*   也可以打压大公司, 比如Ebay，让他们屈服 （“Google told the company it had made a decision to lower the ranking of a large number of eBay pages that were a big source of traffic.”）
*   甚至可以不给理由地干掉小公司 （DealCatcher的例子）

**其他**：

*   Facebook做得更过分（“have taken a more aggressive approach, manually removing problem content and devising rules around what it defines as misinformation. ”）
*   描述了怎么样可以提高google排序的方法（比如freshness，langurage，location，time staying，等等）
