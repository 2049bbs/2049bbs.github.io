---
aid: 2316
cid: 2
authorID: 2809
addTime: 2019-12-19T13:15:00.000Z
title: 本人开发的全站爬虫\网站备份工具
tags:
    - 全站
    - 爬虫
    - 备份
    - 网站
    - 工具
comments:
    -
        authorID: 1
        addTime: 2019-12-19T18:00:00.000Z
        content: 楼主有心人呀
    -
        authorID: 2683
        addTime: 2019-12-20T02:30:00.000Z
        content: >-
            关于文革资料，推荐备份一下香港中文大学中国研究服务中心主办的民间历史


            [http://mjlsh.usc.cuhk.edu.hk/Default.aspx](http://mjlsh.usc.cuhk.edu.hk/Default.aspx)
    -
        authorID: 2683
        addTime: 2019-12-20T02:45:00.000Z
        content: >-
            另外，既然楼主能生成Gohugo子站，不妨搜集一些优秀的网络大V作品，比方Reddit/u/Spinkcat的发言很不错，如果能把下面的文档按主题切分成文章，做一个/CNRedditors
            挂在你下面就好了，现在这个文档太大根本打不开。


            [https://gitlab.com/redditcollection/chinese-redditors/blob/master/Spinkcat\_comments.md](https://gitlab.com/redditcollection/chinese-redditors/blob/master/Spinkcat_comments.md)


            如果这个repo的楼主能把抓取reddit内容的代码开源就好了，可以搜集一些优秀的答主
    -
        authorID: 2452
        addTime: 2019-12-20T02:45:00.000Z
        content: 哇感谢感谢，实用工具
    -
        authorID: 2683
        addTime: 2019-12-20T02:45:00.000Z
        content: >-
            还有pin站早期的优秀答主的发言像利维坦、Merlin（Pepperonie）的也可以搜集一些，直接从它的公开的数据库里面提取即可。总觉得有些优秀答主现在散了挺可惜的，想搜集起来做个档案。Spinkcat一直在产出内容，非常赏心悦目。
    -
        authorID: 2809
        addTime: 2019-12-20T08:00:00.000Z
        content: >-
            @[新闻实验室](/member/%E6%96%B0%E9%97%BB%E5%AE%9E%E9%AA%8C%E5%AE%A4) #5
            提供的内容非常不错，不过本人时间和精力有限很难兼顾多个方向。


            你提到的 Spinkcat 在 Reddit 的留言有了解，但是这部分内容属于个人创作，需要向对方申请版权。


            本人项目中的 1 内容虽然是由海外学者整理出版，在某些学校图书馆可以公开查阅，但本人认为其设计的事件对中国影响非常之大，且若干在线资源被
            GFW 认证，大陆若想了解相关的资源颇有难度，因此花时间整理。


            对于本人整理的 2，3 同理，目前更着重于科学研究价值较大、国内被和谐或在国内不易访问的内容。


            当然，对于你提到的一些内容和方向，本人愿意提供技术支持，一起协作完成。


            另：你提到的 [reddit
            连接](https://gitlab.com/redditcollection/chinese-redditors/blob/master/Spinkcat_comments.md?expanded=true&viewer=rich)
            可以点 load it anyway 或其他两个选项均可以查看，如若不可还可以把项目 clone 到本地查看。
    -
        authorID: 2156
        addTime: 2019-12-20T09:00:00.000Z
        content: >-
            @[新闻实验室](/member/%E6%96%B0%E9%97%BB%E5%AE%9E%E9%AA%8C%E5%AE%A4) #5
            六月之前还是有不少大手写的东西可看的。大约18年底到19年年初附近。


            如果要抓内容可先抓特定时间段的某些id，但最好是先格式化下，有不少好的回答都淹没在很多普通问题下，而且也不是我们认证过的那些id，很多都是匿名的。


            有的人说的内容到年底年中都得到了验证
    -
        authorID: 2156
        addTime: 2019-12-20T09:15:00.000Z
        content: >-
            @[新闻实验室](/member/%E6%96%B0%E9%97%BB%E5%AE%9E%E9%AA%8C%E5%AE%A4) #5
            刚用google搜索站内了下，发现有的话题讨论已经被删除或者隐藏了，以前我都是截图保存有用或有意思的回答的，现在看，真正包含信息量的讨论还真的不能人多，人一多说真话的人就会走。
    -
        authorID: 2156
        addTime: 2019-12-20T09:15:00.000Z
        content: 不过可以比较出来 duckduckgo的搜索质量是非常之低。大部分内容都index不到。
    -
        authorID: 2683
        addTime: 2019-12-21T00:15:00.000Z
        content: >-
            @[sorrysorrysorry](/member/sorrysorrysorry) #7
            @[hello](/member/hello) \_chris #6
            谢谢提醒，版权问题我觉得公共论坛的发言本身就是属于公共领域，只要引用注明出处和ID应该问题不大，版权还是原作者的，没有授权的话跟CDT差不多，虽然然CDT也常被人吐嘈。
    -
        authorID: 2903
        addTime: 2020-01-10T07:30:00.000Z
        content: >-
            @[hello](/member/hello) \_chris #6
            能否把www.cnd.org备份一下？30岁的网站，真正的互联网活化石，里头宝很多，但网站安全性实在糟心。
    -
        authorID: 2903
        addTime: 2020-01-10T07:45:00.000Z
        content: >-
            都不知道网站是什么语言写的，
            [http://museums.cnd.org/CR/ZK16/cr878.gb.html](http://museums.cnd.org/CR/ZK16/cr878.gb.html)
            随便打开一个文章链接，其源代码基本上等于看到的文字。


            不过我还蛮欣赏华夏文摘的极简纯文字风，做博客模版的大神可以尝试复兴一下这种风格
date: 2020-01-10T07:45:00.000Z
category: 时政
---

本项目的缘起是由于查询 `文化大革命时期` 中使用到的大字报及官方通告等宣传物料，于是通过 Google 发现 [https://ccradb.appspot.com/](https://ccradb.appspot.com/) 和 [无产阶级图书馆](https://library.proletarian.me/download.php?book=%E4%B8%AD%E5%9B%BD%E6%96%87%E5%8C%96%E5%A4%A7%E9%9D%A9%E5%91%BD%E6%96%87%E5%BA%93&link=books%2F58eebcc7f061d4789fb2757c1c9b964e.zip) 分别提供全文阅览及光盘版下载，但考虑到第一个站 appspot 已被 GFW 认证，而第二个站则需要 Windows 操作系统(本人Macos)，使用和查询并不方便，于是想到了将其全站下载并开放在 Github 方便其他人查询使用。

因此诞生了本项目，如果熟悉 Python 和 Scrapy，写一个爬虫，只需要十几行代码，耗时半小时到若干小时不等，再配合 Gohugo 等静态网站生成器，可以很方便的利用 Github Pages 生成一个全新的没有被 GFW 认证的网站。

[https://github.com/speechfree/wholesite-crawler](https://github.com/speechfree/wholesite-crawler)

通过此工具爬取的整站目前有如下几个：

1.  ccradb 中国文化大革命文库 [https://speechfree.github.io/cultural-revolution-database/](https://speechfree.github.io/cultural-revolution-database/)
2.  xys 新语丝 [https://speechfree.github.io/xys/](https://speechfree.github.io/xys/)
3.  letscorp 墙外楼 [https://speechfree.github.io/letscorp/](https://speechfree.github.io/letscorp/)

欢迎各位添加新的爬虫
