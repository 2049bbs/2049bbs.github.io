---
aid: 2316
cid: 2
authorID: 2809
addTime: 2019-12-19T13:15:00.000Z
title: 本人开发的全站爬虫\网站备份工具
tags:
    - 全站
    - 爬虫
    - 备份
    - 网站
    - 工具
comments:
    -
        authorID: 1
        addTime: 2019-12-19T18:00:00.000Z
        content: 楼主有心人呀
    -
        authorID: 2683
        addTime: 2019-12-20T02:30:00.000Z
        content: >-
            关于文革资料，推荐备份一下香港中文大学中国研究服务中心主办的民间历史


            [http://mjlsh.usc.cuhk.edu.hk/Default.aspx](http://mjlsh.usc.cuhk.edu.hk/Default.aspx)
    -
        authorID: 2683
        addTime: 2019-12-20T02:45:00.000Z
        content: >-
            另外，既然楼主能生成Gohugo子站，不妨搜集一些优秀的网络大V作品，比方Reddit/u/Spinkcat的发言很不错，如果能把下面的文档按主题切分成文章，做一个/CNRedditors
            挂在你下面就好了，现在这个文档太大根本打不开。


            [https://gitlab.com/redditcollection/chinese-redditors/blob/master/Spinkcat\_comments.md](https://gitlab.com/redditcollection/chinese-redditors/blob/master/Spinkcat_comments.md)


            如果这个repo的楼主能把抓取reddit内容的代码开源就好了，可以搜集一些优秀的答主
    -
        authorID: 2452
        addTime: 2019-12-20T02:45:00.000Z
        content: 哇感谢感谢，实用工具
    -
        authorID: 2683
        addTime: 2019-12-20T02:45:00.000Z
        content: >-
            还有pin站早期的优秀答主的发言像利维坦、Merlin（Pepperonie）的也可以搜集一些，直接从它的公开的数据库里面提取即可。总觉得有些优秀答主现在散了挺可惜的，想搜集起来做个档案。Spinkcat一直在产出内容，非常赏心悦目。
    -
        authorID: 2809
        addTime: 2019-12-20T08:00:00.000Z
        content: >-
            @[新闻实验室](/member/%E6%96%B0%E9%97%BB%E5%AE%9E%E9%AA%8C%E5%AE%A4) #5
            提供的内容非常不错，不过本人时间和精力有限很难兼顾多个方向。


            你提到的 Spinkcat 在 Reddit 的留言有了解，但是这部分内容属于个人创作，需要向对方申请版权。


            本人项目中的 1 内容虽然是由海外学者整理出版，在某些学校图书馆可以公开查阅，但本人认为其设计的事件对中国影响非常之大，且若干在线资源被
            GFW 认证，大陆若想了解相关的资源颇有难度，因此花时间整理。


            对于本人整理的 2，3 同理，目前更着重于科学研究价值较大、国内被和谐或在国内不易访问的内容。


            当然，对于你提到的一些内容和方向，本人愿意提供技术支持，一起协作完成。


            另：你提到的 [reddit
            连接](https://gitlab.com/redditcollection/chinese-redditors/blob/master/Spinkcat_comments.md?expanded=true&viewer=rich)
            可以点 load it anyway 或其他两个选项均可以查看，如若不可还可以把项目 clone 到本地查看。
date: 2019-12-20T08:00:00.000Z
category: 时政
---

本项目的缘起是由于查询 `文化大革命时期` 中使用到的大字报及官方通告等宣传物料，于是通过 Google 发现 [https://ccradb.appspot.com/](https://ccradb.appspot.com/) 和 [无产阶级图书馆](https://library.proletarian.me/download.php?book=%E4%B8%AD%E5%9B%BD%E6%96%87%E5%8C%96%E5%A4%A7%E9%9D%A9%E5%91%BD%E6%96%87%E5%BA%93&link=books%2F58eebcc7f061d4789fb2757c1c9b964e.zip) 分别提供全文阅览及光盘版下载，但考虑到第一个站 appspot 已被 GFW 认证，而第二个站则需要 Windows 操作系统(本人Macos)，使用和查询并不方便，于是想到了将其全站下载并开放在 Github 方便其他人查询使用。

因此诞生了本项目，如果熟悉 Python 和 Scrapy，写一个爬虫，只需要十几行代码，耗时半小时到若干小时不等，再配合 Gohugo 等静态网站生成器，可以很方便的利用 Github Pages 生成一个全新的没有被 GFW 认证的网站。

[https://github.com/speechfree/wholesite-crawler](https://github.com/speechfree/wholesite-crawler)

通过此工具爬取的整站目前有如下几个：

1.  ccradb 中国文化大革命文库 [https://speechfree.github.io/cultural-revolution-database/](https://speechfree.github.io/cultural-revolution-database/)
2.  xys 新语丝 [https://speechfree.github.io/xys/](https://speechfree.github.io/xys/)
3.  letscorp 墙外楼 [https://speechfree.github.io/letscorp/](https://speechfree.github.io/letscorp/)

欢迎各位添加新的爬虫
